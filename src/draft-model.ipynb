{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34d6be9-84b2-40eb-9836-508d6f7b627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080.5616763076455\n",
      "1393.5525470410078\n",
      "934.943341517506\n",
      "628.6271477140692\n",
      "423.90954487469514\n",
      "287.0072425256562\n",
      "195.3959151554812\n",
      "134.05034892148686\n",
      "92.942416357208\n",
      "65.37541550828848\n",
      "46.87472838917273\n",
      "34.44866196732138\n",
      "26.095711525658583\n",
      "20.4759307888735\n",
      "16.69163849725867\n",
      "14.141004581071398\n",
      "12.42023902692171\n",
      "11.258210158476759\n",
      "10.472712711890384\n",
      "9.94119750412294\n",
      "Result: y = 0.022374646125949478 + 0.8314440858527752 x + -0.003859998772444895 x^2 + -0.08973214561201026 x^3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for i in range(2000):\n",
    "  y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "  loss = np.square(y_pred - y).sum()\n",
    "\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_a = grad_y_pred.sum()\n",
    "  grad_b = (grad_y_pred * x).sum()\n",
    "  grad_c = (grad_y_pred * x ** 2).sum()\n",
    "  grad_d = (grad_y_pred * x ** 3).sum()\n",
    "  \n",
    "  if i % 100 == 99:\n",
    "    print(loss)\n",
    "    \n",
    "  a -= learning_rate * grad_a\n",
    "  b -= learning_rate * grad_b\n",
    "  c -= learning_rate * grad_c\n",
    "  d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b3c183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running MPS\n",
      "257.56402587890625\n",
      "173.6973876953125\n",
      "118.12605285644531\n",
      "81.29692077636719\n",
      "56.8856201171875\n",
      "40.7022705078125\n",
      "29.971858978271484\n",
      "22.855714797973633\n",
      "18.135570526123047\n",
      "15.003992080688477\n",
      "12.925908088684082\n",
      "11.546592712402344\n",
      "10.630847930908203\n",
      "10.022743225097656\n",
      "9.618809700012207\n",
      "9.350395202636719\n",
      "9.17198371887207\n",
      "9.053364753723145\n",
      "8.974461555480957\n",
      "8.921964645385742\n",
      "Result: y = -0.0036701629869639874 + 0.8473776578903198 x + 0.0006331619806587696 x^2 + -0.09199855476617813 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print (f\"running {device}\")\n",
    "\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for i in range(2000):\n",
    "  y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "  loss = (y_pred - y).pow(2).sum().item()\n",
    "\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_a = grad_y_pred.sum()\n",
    "  grad_b = (grad_y_pred * x).sum()\n",
    "  grad_c = (grad_y_pred * x ** 2).sum()\n",
    "  grad_d = (grad_y_pred * x ** 3).sum()\n",
    "  \n",
    "  if i % 100 == 99:\n",
    "    print(loss)\n",
    "    \n",
    "  a -= learning_rate * grad_a\n",
    "  b -= learning_rate * grad_b\n",
    "  c -= learning_rate * grad_c\n",
    "  d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ced1737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running mps with torch.float32 dtype\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "torch.set_default_device(device)\n",
    "# TypeError: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
    "dtype = torch.float32 if device.type == 'mps' else torch.float\n",
    "torch.set_default_dtype(dtype)\n",
    "print (f\"running {device} with {dtype} dtype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdfd2e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(207.6785, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(140.8889, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(96.5562, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(67.1224, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(47.5752, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5899, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9614, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(20.2260, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(16.4123, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(13.8756, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(12.1876, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(11.0640, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(10.3157, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(9.8171, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(9.4848, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2632, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(9.1153, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(9.0166, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(8.9506, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(8.9066, device='mps:0', grad_fn=<MseLossBackward0>)\n",
      "Result: y = -0.004409109707921743 + 0.8484901785850525 x + 0.0007606451981700957 x^2 + -0.0921567976474762 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "powers = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(powers)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(3, 1),\n",
    "  torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for i in range(2000):\n",
    "\n",
    "  y_pred = model(xx)\n",
    "\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  \n",
    "  if i % 100 == 99:\n",
    "    print(loss)\n",
    "    \n",
    "  model.zero_grad()\n",
    "\n",
    "  loss.backward() # TODO why loss does backprop, and not model\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "      param -= learning_rate * param.grad\n",
    "\n",
    "linear_layer = model[0]\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc0c9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/-19.931_89368010.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/-19.809_81749056_9057.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/-21.575_80310840a.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/9.013_71601299.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/24.399_0011973451.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/-21.575_80310840a.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/2.213_91914407.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/16.963_0011976929.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/-13.466_00838511_00838525.png', '/Users/mp/projects/ml/innora-document-deskew/dataset/training_data/images/16.963_0011976929.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mp/projects/ml/innora-document-deskew/venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "from torchvision import transforms\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "images_dir_path = f\"{os.path.dirname(os.getcwd())}/dataset/training_data/images\"\n",
    "image_paths = glob.glob(os.path.join(images_dir_path, \"*\"))\n",
    "image_paths = list(np.random.choice(image_paths, size=10))\n",
    "print(image_paths)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Resize((500, 500))\n",
    "])\n",
    "\n",
    "for image_path in image_paths:\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('L')               # open image as PIL Image\n",
    "    img_tensor = transform(img)                                         # convert PIL Image to np array\n",
    "    images.append(img_tensor)\n",
    "    skew_angle_str = os.path.basename(image_path).split('_')[0]\n",
    "    skew_angle = torch.tensor(float(skew_angle_str) + 30).to(torch.long)\n",
    "    labels.append(skew_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c0e3301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " 10,\n",
       " tensor(10),\n",
       " torch.Size([1, 500, 500]),\n",
       " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.5999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.7571, 0.1564, 0.3810, 0.9039, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.9933, 0.8149, 0.6139, 0.7024, 0.4099,\n",
       "         0.7052, 0.9981, 1.0000, 1.0000, 1.0000, 1.0000, 0.8441, 0.6325, 0.6690,\n",
       "         0.1876, 0.8268, 0.6119, 0.9885, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         0.9993, 1.0000, 0.8604, 0.3441, 0.4782, 0.9851, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         0.9698, 0.7616, 0.4344, 0.2866, 0.2506, 0.6981, 0.7972, 0.9987, 0.9912,\n",
       "         0.3766, 0.7129, 0.2529, 0.9529, 0.3402, 0.8943, 0.6863, 0.7410, 1.0000,\n",
       "         0.9161, 0.1482, 0.9826, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9838, 0.8934, 0.5570, 0.2217,\n",
       "         0.2210, 0.4734, 0.8367, 0.9678, 1.0000, 1.0000, 1.0000, 0.9972, 0.6794,\n",
       "         0.3491, 0.2687, 0.6174, 0.8907, 0.5459, 0.5863, 0.9817, 1.0000, 0.9974,\n",
       "         0.7314, 0.7899, 0.9963, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.9944, 0.7840, 0.5323, 0.3066, 0.5339, 0.7256,\n",
       "         0.8721, 0.4395, 0.5031, 0.9293, 0.8182, 0.6343, 0.9192, 0.3996, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 0.9666, 0.6559, 0.2563, 0.0050, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( len(images), len(labels), labels[0], images[0].size(), images[0][0][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebdcd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_list, labels):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.img_list = img_list\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\"data\": self.img_list[idx], \"target\": self.labels[idx] }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97fd0ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "10\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.184998989105225 hypothesis: tensor([11]) y: tensor([10])\n",
      "1 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "10\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.187053680419922 hypothesis: tensor([11]) y: tensor([10])\n",
      "2 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "8\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.173307418823242 hypothesis: tensor([11]) y: tensor([8])\n",
      "3 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "39\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.284471035003662 hypothesis: tensor([30]) y: tensor([39])\n",
      "4 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "54\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.042973041534424 hypothesis: tensor([30]) y: tensor([54])\n",
      "5 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "8\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.173227787017822 hypothesis: tensor([11]) y: tensor([8])\n",
      "6 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "32\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.041530609130859 hypothesis: tensor([31]) y: tensor([32])\n",
      "7 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "46\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.012481689453125 hypothesis: tensor([30]) y: tensor([46])\n",
      "8 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "16\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.175495147705078 hypothesis: tensor([35]) y: tensor([16])\n",
      "9 torch.Size([1, 1, 500, 500]) torch.Size([1])\n",
      "cpu\n",
      "46\n",
      "torch.Size([1, 61]) torch.Size([1])\n",
      "loss 4.012393474578857 hypothesis: tensor([30]) y: tensor([46])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(\n",
    "        1,  # if B&W else 3,\n",
    "        12,  # number of kernels - we need less as we only detect vertical/horizontal/diagonal lines\n",
    "        3,  # kernel size\n",
    "        1,  # 1 pixel at a time\n",
    "        1  # padding - kernel size / 2 - to apply kernel on borders\n",
    "    ),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Conv2d(12, 24, kernel_size=3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Flatten(),  # Flatten the tensor\n",
    "    # Adjust the input size based on your image size\n",
    "    torch.nn.Linear(24 * 125 * 125, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(\n",
    "        128,  # number of kernels\n",
    "        30 + 1 + 30,  # [-30, 30] degrees\n",
    "        # bias=True # TODO try without\n",
    "    ),\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss(\n",
    "    reduction='sum')  # TODO why cross entropy?\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(MyDataset(images, labels))\n",
    "\n",
    "for idx, sample in enumerate(train_loader):\n",
    "    x, y = sample['data'], sample['target']\n",
    "    print(idx, x.size(), y.size())\n",
    "# for x,y in zip(images, labels):\n",
    "    # x, y = data.to(device), target\n",
    "    # x = torch.tensor(images) # images             ->    Width x Height x Amount ( B&W or dim for rgb? )\n",
    "    # y = torch.tensor(labels) # skew angle labels  ->    Amount\n",
    "    # for i in range(epochs):\n",
    "    print(next(model.parameters()).device)\n",
    "    hypothesis = model(x)\n",
    "    print(y.item())\n",
    "    print(hypothesis.size(), y.size())\n",
    "    loss = criterion(hypothesis, y)\n",
    "    print(f\"loss {loss} hypothesis: {hypothesis.argmax(dim=1)} y: {y}\")\n",
    "    optimizer.zero_grad()  # TODO why\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f531b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
